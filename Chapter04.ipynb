{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497c0f3a",
   "metadata": {},
   "source": [
    "# 网络结构的可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d37b9f3",
   "metadata": {},
   "source": [
    "## 准备网络和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70938bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "from torch.optim import SGD\n",
    "import torch.utils.data as Data\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c37b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用手写字体数据，准备训练数据集\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = True, # 之使用训练数据集\n",
    "    # 将数据转化为torch使用的张量，取值范围为[0,1]\n",
    "    transform = torchvision.transforms.ToTensor(),\n",
    "    download = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32562474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "test_data_x.shape: torch.Size([10000, 1, 28, 28])\n",
      "test_data_y.shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# 定义一个数据加载器\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_data,  # 数据集\n",
    "    batch_size=128,  # 批处理样本大小\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "# 获得一个batch的数据\n",
    "for step, (b_x, b_y) in enumerate(train_loader):\n",
    "    if step > 0:\n",
    "        break\n",
    "\n",
    "# 输出训练图像的尺寸和标签的尺寸\n",
    "print(b_x.shape)\n",
    "print(b_y.shape)\n",
    "\n",
    "# 准备需要使用的测试数据集\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='./data/MNIST',\n",
    "    train=False,  # 不使用训练数据集\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "# 为数据添加一个通道纬度，并且取值范围缩放到0到1之间\n",
    "test_data_x = test_data.data.type(torch.FloatTensor) / 255.0\n",
    "test_data_x = torch.unsqueeze(test_data_x, dim=1)\n",
    "test_data_y = test_data.targets  # 测试集的标签\n",
    "\n",
    "print(\"test_data_x.shape:\", test_data_x.shape)\n",
    "print(\"test_data_y.shape:\", test_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23cd6774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建一个卷积神经网络\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # 定义第一个卷积层\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,    # 输入的feature map\n",
    "                out_channels=16,  # 输出的feature map\n",
    "                kernel_size=3,    # 卷积核尺寸\n",
    "                stride=1,         # 卷积核步长\n",
    "                padding=1,        # 进行填充\n",
    "            ),\n",
    "            nn.ReLU(),            # 激活函数\n",
    "            nn.AvgPool2d(\n",
    "                kernel_size=2,    # 平均值池化层，使用2x2\n",
    "                stride=2,         # 池化步长为2\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # 定义第二个卷积层\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,    # 输入的feature map\n",
    "                out_channels=32,  # 输出的feature map\n",
    "                kernel_size=3,    # 卷积核尺寸\n",
    "                stride=1,         # 卷积核步长\n",
    "                padding=1,        # 进行填充\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)     # 最大值池化\n",
    "        )\n",
    "\n",
    "        # 定义全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=32*7*7,  # 输入特征\n",
    "                out_features=128,   # 输出特征数\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(\n",
    "                in_features=128,  # 输入特征\n",
    "                out_features=64,   # 输出特征数\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 定义分类层\n",
    "        self.out = nn.Linear(64, 10)\n",
    "\n",
    "    # 定义网络的向前传播路径\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)   # 展平多维的卷积图层\n",
    "        x = self.fc(x)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f4712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1568, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 输出网络结构\n",
    "MyConvnet = ConvNet()\n",
    "print(MyConvnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf26ec",
   "metadata": {},
   "source": [
    "## HiddenLayer库可视化网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbf3edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hiddenlayer as hl\n",
    "\n",
    "# 可视化卷积神经网络\n",
    "hl_graph = hl.build_graph(MyConvnet, torch.zeros([1, 1, 28, 28]))\n",
    "hl_graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "\n",
    "# 将可视化的网络保存为图片\n",
    "hl_graph.save('./data/net/chapter4/MyConvnet_hl.png', format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb47f80",
   "metadata": {},
   "source": [
    "## PyTorchViz库可视化网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5206afc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\net\\\\chapter4\\\\MyConvnet_vis\\\\Digraph.gv.pdf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "# 使用make_dot可视化网络\n",
    "x = torch.randn(1, 1, 28, 28).requires_grad_(True)\n",
    "y = MyConvnet(x)\n",
    "MyConvnetvis = make_dot(y, params=dict(list(MyConvnet.named_parameters())+[('x',x)]))\n",
    "\n",
    "# 指定文件保存位置\n",
    "MyConvnetvis.directory = './data/net/chapter4/MyConvnet_vis'\n",
    "MyConvnetvis.view() # 会自动在当前文件夹生成文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65948e4",
   "metadata": {},
   "source": [
    "# 训练过程的可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8991b",
   "metadata": {},
   "source": [
    "## tensorboardX中的常用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596abfc",
   "metadata": {},
   "source": [
    "<center><b>tensorboardX常用功能和调用方式</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f9aa2",
   "metadata": {},
   "source": [
    "| 函数 | 功能 | 用法 |\n",
    "| :---- | :---- | :---- |\n",
    "| SummaryWriter() | 创建编写器，保存日志 | writer=SummaryWriter() |\n",
    "| writer.add_scalar() | 添加标量 | writer.add_scalar('myscalar',value,iteration) |\n",
    "| writer.add_image()() | 添加图像 | writer.add_image('imresult',x,iteration) |\n",
    "| writer.add_histogram()() | 添加直方图 | writer.add_histogram('hist',array,iteration) |\n",
    "| writer.add_graph()() | 添加网络结构 | writer.add_graph(model,input_to_model=None) |\n",
    "| writer.add_audio()() | 添加音频 | writer.add_audio(tag,audio,iteration,sample_rate) |\n",
    "| writer.add_text()() | 添加文本 | writer.add_text(tag,text_string,global_step=None) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3023bd",
   "metadata": {},
   "source": [
    "## 利用tensorboardX进行可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03dcf55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从tensorboardX库中导入需要的API\n",
    "from tensorboardX import SummaryWriter\n",
    "SumWriter = SummaryWriter(log_dir='./data/log/chapter4')\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(MyConvnet.parameters(), lr=0.0003)\n",
    "loss_func = nn.CrossEntropyLoss() # 损失函数\n",
    "train_loss = 0\n",
    "print_step = 100 # 每经过100次迭代后，输出损失\n",
    "\n",
    "# 对模型进行迭代训练，对所有的数据训练epoch轮\n",
    "for epoch in range(5):\n",
    "    # 对训练数据的加载器进行迭代计算\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        # 计算每个batch的损失\n",
    "        output = MyConvnet(b_x)          # CNN在训练batch上的输出\n",
    "        loss = loss_func(output, b_y)    # 交叉熵损失函数\n",
    "        optimizer.zero_grad()            # 每个迭代的梯度初始化为0\n",
    "        loss.backward()                  # 损失的后向传播，计算梯度\n",
    "        optimizer.step()                 # 使用梯度进行优化\n",
    "        train_loss = train_loss + loss   # 计算损失的累加损失\n",
    "        \n",
    "        # 计算迭代次数\n",
    "        niter = epoch * len(train_loader) + step + 1\n",
    "        \n",
    "        # 计算每经过print_step次迭代后的输出\n",
    "        if niter % print_step == 0:\n",
    "            # 为日志添加训练集损失函数\n",
    "            SumWriter.add_scalar('train loss', train_loss.item()/niter, global_step=niter)\n",
    "            \n",
    "            # 计算在测试集上的精度\n",
    "            output = MyConvnet(test_data_x)\n",
    "            _, pre_lab = torch.max(output, 1)\n",
    "            acc = accuracy_score(test_data_y, pre_lab)\n",
    "            \n",
    "            # 为日志中添加训练数据的可视化图像，使用当前batch的图像\n",
    "            # 将一个batch的数据进行预处理\n",
    "            b_x_im = vutils.make_grid(b_x, nrow=12)\n",
    "            SumWriter.add_image('train image sample', b_x_im, niter)\n",
    "            \n",
    "            # 使用直方图可视化网络中参数的分布情况\n",
    "            for name, param in MyConvnet.named_parameters():\n",
    "                SumWriter.add_histogram(name, param.data.numpy(), niter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b8b9a",
   "metadata": {},
   "source": [
    "## 查看tensorboardX可视化结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38657d20",
   "metadata": {},
   "source": [
    "## HiddenLayer库可视化训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc3bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 见书93-94页"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f4b9e",
   "metadata": {},
   "source": [
    "# 第四章后续见书95-101页"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "563.2px",
    "left": "111px",
    "top": "-5.988px",
    "width": "220.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
